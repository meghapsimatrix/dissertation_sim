---
title: 'A meta-analysis of the facial feedback hypothesis'
output:
  pdf_document: default
  html_document: default
  word_document: default
authors: Nicholas A. Coles
editor_options: 
  chunk_output_type: console
---
***READ ME****
This is the code for a meta-analysis on the facial feedback literature.

The code was written in R version 3.4.0 using R Markdown (http://rmarkdown.rstudio.com/). It is recommended that users download this package before proceeding. In R Markdown, the user can view the document outline by pressing Ctrl+Shift+O (on Windows). This outline will help the user navigate the structure of the code.

This code was written by Nicholas A. Coles with assistance from Ashley Kuelz. Please direct questions to ncoles797@gmail.com

#****Section 1: Data Prep****
```{r setup and load packages}
# change knitr settings
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
  
# clear environment
rm(list = ls())
  
# install (if necessary) and load packages
if (!require(readxl)) {
  install.packages('readxl')
}

if (!require(metafor)) {
  install.packages('metafor')
}

if (!require(esc)) {
  install.packages('esc')
}
  
if (!require(robumeta)) {
  install.packages('robumeta')
}

if (!require(MAd)) {
  install.packages('MAd')
}

if (!require(dplyr)) {
  install.packages('dplyr')
}

if (!require(weightr)) {
  install.packages('weightr')
}

if (!require(clubSandwich)) {
  install.packages('clubSandwich')
}

library("readxl")
library("metafor")
library("esc")
library("robumeta")
library("MAd")
library("dplyr")
library("weightr")
library("clubSandwich")
  

#turn scientific notation off
options(scipen = 999)
```

```{r prep data}
# import data
FFH.DF <- read_excel("ffh.meta_data_raw.xlsx",
                     sheet = "ES spreadsheet",
                     na = "N/A")

   
# delete unnecessary variables
  # create list of unnecessary variables
  myvars <- names(FFH.DF) %in% c(
    "total.n",
    "review.notes",
    "ref1",
    "ref2",
    "ref3",
    "ref4",
    "ref5",
    "ref6",
    "ref7",
    "emo.measure",
    "ref8",
    "ref9",
    "ref10",
    "ref11",
    "ref12",
    "ref13",
    "proc.desc",
    "flipped",
    "ref14",
    "ref15",
    "n.ref16",
    "es.ref17",
    "notes1",
    "notes2",
    "notes3",
    "notes4")
    
    # remove list of unnecessary variables from dataset 
    FFH.DF <- FFH.DF[!myvars]
    rm(myvars)
      
# transform moderators into factors
FFH.DF$assumed <- factor(FFH.DF$assumed)
FFH.DF$file.drawer <- factor(FFH.DF$file.drawer)
FFH.DF$video.know <- factor(FFH.DF$video.know)
FFH.DF$dim.v.dis <- factor(FFH.DF$dim.v.dis)
FFH.DF$dim.pos.v.neg <- factor(FFH.DF$dim.pos.v.neg)
FFH.DF$emo <- factor(FFH.DF$emo)
FFH.DF$dur.manip <- factor(FFH.DF$dur.manip)
FFH.DF$paq <- factor(FFH.DF$paq)
FFH.DF$ini.v.mod <- factor(FFH.DF$ini.v.mod)
FFH.DF$stim <- factor(FFH.DF$stim)
FFH.DF$proc <- factor(FFH.DF$proc)
FFH.DF$proc.control <- factor(FFH.DF$proc.control)
FFH.DF$proc.aware <- factor(FFH.DF$proc.aware)
FFH.DF$w.v.b <- factor(FFH.DF$w.v.b)

# transform publication year into a continuous variable
# Note: unpublished datasets w/ no documented year will be coded as N/A
FFH.DF$year <- as.numeric(FFH.DF$year)

# create blank columns for effect size and effect size variance
# pre-exisiting columns are necessary for Cohen d functions to work
FFH.DF$es <- NA
FFH.DF$es.var <- NA
```


# Calculate Cohen's d and variance
## For between-subjects data
### Functions for calculating d 
#### When M's and SD's are provided
```{r define function EsBetwMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 226
EsBetwMean <- function(n.1, m.1, sd.1, 
                       n.2, m.2, sd.2){
    sd.within <- sqrt((((n.1 - 1) * (sd.1^2)) +
                       ((n.2 - 1) * (sd.2^2))) /
                        (n.1 + n.2 - 2));
    
    es <- (m.1 - m.2) / sd.within;
    return(es)
}
```

#### When t-values are provided
```{r define function EsBetwTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwTval <- function(n.1, n.2, tval){
    es <- tval * sqrt((n.1 + n.2) / 
                      (n.1 * n.2));
    return(es)
}
```

#### When F-values are provided
```{r define function EsBetwFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwFval <- function(n.1, n.2, fval, direction){
  es <- sqrt((fval * (n.1 + n.2)) / 
             (n.1 * n.2));
  
  if (direction == "negative"){
    es <- es * (-1)
  }
  return(es)
}
```

#### When p-values are provided
```{r define function EsBetwPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsBetwPval <- function(n.1, n.2, pval, pval.df, direction){
  # calculate the inverse of the cumulative distribution function of t
  t.inv <- qt(p = (pval / 2), 
              df = pval.df,
              lower.tail = FALSE);
  
  es <- t.inv * sqrt((n.1 + n.2) /
                     (n.1 * n.2));
  
  if (direction == "negative"){
    es <- es * (-1)
  }
  return(es)
}
```

### Function for calculating variance of d
```{r define function EsVarBetw}
# formula: Cooper, Hedges, & Valentine, 2009; p. 228
EsVarBetw <- function(n.1, n.2, es){       
   es.var <- ((n.1 + n.2) / (n.1 * n.2)) +
             ((es^2) / (2 * (n.1 + n.2)));
   return(es.var)
}
```

### Call functions to calculate d and variance of d
```{r b: call functions to calculate d}
# call EsBetwMean on cases with between-subject designs and *means*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "between" & FFH.DF$es.calc.method[i] == "mean") {
    FFH.DF$es[i] <- EsBetwMean (n.1 = FFH.DF$b.treat.n[i],
                                m.1 = FFH.DF$b.treat.m[i],
                                sd.1 = FFH.DF$b.treat.sd[i],
                                n.2 = FFH.DF$b.compa.n[i],
                                m.2 = FFH.DF$b.compa.m[i],
                                sd.2 = FFH.DF$b.compa.sd[i])
  }
}

# call EsBetwTval on cases with between-subject designs and *t-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "between" & FFH.DF$es.calc.method[i] == "tval") {
    FFH.DF$es[i] <- EsBetwTval (n.1 = FFH.DF$b.treat.n[i],
                                n.2 = FFH.DF$b.compa.n[i],
                                tval = FFH.DF$b.tval[i])
  }
}

# call EsBetwFval on cases with between-subject designs and *F-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "between" & FFH.DF$es.calc.method[i] == "fval") {
    FFH.DF$es[i] <- EsBetwFval (n.1 = FFH.DF$b.treat.n[i],
                                n.2 = FFH.DF$b.compa.n[i],
                                fval = FFH.DF$b.fval[i],
                                direction = FFH.DF$es.dir.fpval[i])
  }
}

# call EsBetwPval on cases with between-subject designs and *p-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "between" & FFH.DF$es.calc.method[i] == "pval") {
    FFH.DF$es[i] <- EsBetwPval (n.1 = FFH.DF$b.treat.n[i],
                                n.2 = FFH.DF$b.compa.n[i],
                                pval = FFH.DF$b.pval[i],
                                pval.df = FFH.DF$b.pval.df[i],
                                direction = FFH.DF$es.dir.fpval[i])
  }
}
```

```{r b: call function to calculate variance of d}
# call EsVarBetw on cases with between subject designs
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "between") {
    FFH.DF$es.var[i] <- EsVarBetw (n.1 = FFH.DF$b.treat.n[i],
                                   n.2 = FFH.DF$b.compa.n[i],
                                   es = FFH.DF$es[i])
  }
}
```


## For within-subjects data
```{r assumed correlation}
# define assumed correlation (sensitivity analyses performed later)
corr <- .5
```

### Functions for calculating d
#### When M's and SD's are provided 
```{r EsWitnMean}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
# formula for imputing sd.diff:
# http://handbook.cochrane.org/chapter_16/16_4_6_1_mean_differences.htm
EsWitnMean <- function(m.1, sd.1, m.2, sd.2, corr){
  sd.diff <- sqrt((sd.1^2) + (sd.2^2) -
                  (2 * corr * sd.1 * sd.2));
        
  es <- ((m.1 - m.2) / sd.diff) * sqrt(2 * (1- corr));
  return(es)
}
```

#### When t-values are provided
```{r EsWitnTval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnTval <- function(n, tval, corr){
  es <- tval * sqrt((2 * (1 - corr)) / n);
  return(es)
}
```

#### When F-values are provided
```{r EsWitnFval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnFval <- function(n, fval, corr, direction){
  es <- sqrt((2 * fval * (1- corr)) / n);

  if (direction == "negative"){
      es <- es * (-1)
  }
  return(es)
}
```

#### When p-values are provided
```{r EsWitnPval}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsWitnPval <- function(n, pval, pval.df, corr, direction){
  # calculate the inverse of the cumulative distribution function of t
  tinv <- qt(p = (pval / 2), 
             df = pval.df,
             lower.tail = FALSE);
  
  es <- tinv * sqrt((2 * (1 - corr)) / n);

  if (direction == "negative"){
    es <- es * (-1)
  }
  return(es)
}
```

### Function for calculating variance of d
```{r EsVarWitn}
# formula: Cooper, Hedges, & Valentine, 2009; p. 229
EsVarWitn <- function(n, es){
  es.var <- ((1 / n) + 
             ((es^2) / (2 * n))) *
            2 * (1 - corr);
  return(es.var)
}
```

### Call functions to calculate d and variance of d
```{r w: call functions to calculate d}
# call EsWitnMean on cases with within-subject designs and *means*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "mean") {
    FFH.DF$es[i] <- EsWitnMean (m.1 = FFH.DF$w.treat.m[i],
                                sd.1 = FFH.DF$w.treat.sd[i],
                                m.2 = FFH.DF$w.compa.m[i],
                                sd.2 = FFH.DF$w.compa.sd[i],
                                corr = corr)
  }
}


# call EsWitnTval on cases with within-subject designs and *t-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "tval") {
    FFH.DF$es[i] <- EsWitnTval (n = FFH.DF$w.n[i],
                                tval = FFH.DF$w.tval[i],
                                corr = corr)
  }
}

# call EsWitnFval on cases with within-subject designs and *F-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "fval") {
    FFH.DF$es[i] <- EsWitnFval (n = FFH.DF$w.n[i],
                                fval = FFH.DF$w.fval[i],
                                corr = corr,
                                direction = FFH.DF$es.dir.fpval[i])
  }
}

# call EsWitnPval on cases with within-subject designs and *p-values*
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "pval") {
    FFH.DF$es[i] <- EsWitnPval (n = FFH.DF$w.n[i],
                                pval = FFH.DF$w.pval[i],
                                pval.df = FFH.DF$w.pval.df[i],
                                corr = corr,
                                direction = FFH.DF$es.dir.fpval[i])
  }
}
```

```{r w: call function to calculate variance of d}
# call EsVarWitn on cases with within subject designs
for (i in 1:nrow(FFH.DF)) {
  if (FFH.DF$w.v.b[i] == "within") {
    FFH.DF$es.var[i] <- EsVarWitn (n = FFH.DF$w.n[i],
                                   es = FFH.DF$es[i])
  }
}

# calculate se of d
FFH.DF$se <- sqrt(FFH.DF$es.var)
```

```{r del var}
# delete unnecessary variables
rm(corr, i)
```

#****Section 2: Level Descriptives****
Perform seperate intercept-only meta-regressions with RVE on each level of each moderator.

Most levels have sufficient observations to perform a meta-regression with RVE. For those, we use the LevelMeta function defined below.

For levels that do not have sufficient observations to perform a meta-regression with RVE, we use a standard random-effects intercept-only meta-regression model.

## Define function
```{r LevelMeta function}
# This code first creates a blank dataframe to paste results in.
# Then, defines a function (LevelMeta) that:
# 1) creates an intercept-only meta-regression with RVE on a user defined dataframe
#    using robumeta function in the robu package
# 2) pastes the results in the results dataframe, 
#    including information from user-defined moderator and level name. 


# create dataframe to paste results in
LEVEL.DESCR <- data.frame()

# define function
LevelMeta <- function(df, level, mod){
  # create intercept-only meta-regression with RVE
  # correcting for correlated dependent effects
  # with no small sample adjustments
  mr.rve.tmp <- robu(formula = es ~ 1,
                     data = df, 
                     studynum = id,
                     var.eff.size = es.var,
                     modelweights = "CORR",
                     small = FALSE)
  
  # paste results in dataframe
  LEVEL.DESCR <<- rbind(LEVEL.DESCR, 
                        cbind(moderator = mod,
                              level = level,
                              es.num = mr.rve.tmp$M,
                              study.num = mr.rve.tmp$N,
                              mr.rve.tmp$reg_table)) #  summary results
}
```

## Call function on moderators with sufficient observations
Note: Meta-regression with RVE will not run with an insufficiently small number of observations. Code for dealing with these exceptions will come next.

```{r LevelMeta on most moderators}
# To calculate the overall effect for each level of each moderator,
# this code creates a list of moderators to run LevelMeta on.
# Using mapply, call LevelMeta for each moderator.
#   - For df argument, split df by moderator using split function
#   - For level argument, use name of moderator levels using names and split function
#   - For mod argument, use name of moderator


# create vector containing moderators with sufficient observations for RVE
moderators <- c("dim.v.dis", "dim.pos.v.neg", "dur.manip", 
                "ini.v.mod", "file.drawer", "paq", 
                "proc", "proc.control", "proc.aware",
                "video.know", "w.v.b", "emo")

# using mapply, call LevelMeta for each moderator
for (m in moderators){
  mapply(FUN = LevelMeta,
         df = split(FFH.DF, FFH.DF[,m]),
         level = names(split(FFH.DF, FFH.DF[,m])),
         mod = m)
}

# remove unnecessary variables
rm(m, moderators)
```

## Call function on stim moderator
Note: three levels of stim (stories, sentences, and imagined scenarios) have too few observations for meta-regression with RVE to run.
In this next code, we first remove those levels and call the LevelMeta function.
In the following code, we will use a standard random-effects intercept-only meta-regression model to examine the levels we had to remove.
```{r LevelMeta function on stim}
# create backup of pristine df
FFH.DF.BACKUP <- FFH.DF

# subset out levels with too few observations 
FFH.DF <- subset(FFH.DF, stim != "stories")
FFH.DF <- subset(FFH.DF, stim != "sentences")
FFH.DF <- subset(FFH.DF, stim != "imagined scenarios")
FFH.DF$stim <- factor(FFH.DF$stim)  # reset factor levels

# using mapply, call LevelMeta for the subsetted stim moderator
mapply(FUN = LevelMeta,
       df = split(FFH.DF, FFH.DF$stim), 
       level = names(split(FFH.DF, FFH.DF$stim)),
       mod = "stim")

# restore pristine dataframe
FFH.DF <- FFH.DF.BACKUP
rm(FFH.DF.BACKUP, LevelMeta)
```

### Examine stim moderator with insufficient observations
```{r examine other levels of stim}
# This code first creates a vector of stim levels with 
# insufficient observations for meta-regression with RVE.
# Then, using lapply, a random-effects intercept-only meta-regression
# is fit for each level in the vector.

# create vector of stim levels with 
# insufficient observations for RVE
stim.list <- c("stories", "sentences", "imagined scenarios")

lapply(stim.list, function(z){
  # subset data
  FFH.DF.TMP <- subset(FFH.DF, stim == z)
  
  # fit a random-effects, intercept-only meta-regression model,
  # using subsetted dataframe
  ffh.mr <- rma.uni(yi = es,
                     vi = es.var,
                     data = FFH.DF.TMP,
                     method = "REML")
  
  # append results to dataframe
  LEVEL.DESCR <<- rbind(LEVEL.DESCR, 
                        cbind(moderator = "stim",
                              level = z,
                              es.num = ffh.mr$k,
                              study.num = "N.A",
                              labels = "X.Intercept.",
                              b.r = as.numeric(ffh.mr$b),
                              SE = ffh.mr$se,
                              t = "N.A",
                              dfs = "N.A",
                              prob = ffh.mr$pval,
                              CI.L = ffh.mr$ci.lb,
                              CI.U = ffh.mr$ci.ub,
                              sig = "N.A"))
})

# remove unnecessary variables
rm(stim.list)
```


#****Section 3: Results****
# Overall Model Results
```{r overall model}
# Calculate the overall effect size using meta-regression with RVE
# using the robu function in the robumeta package.
ffh.overall <- robu(formula = es ~ 1,
                    data = FFH.DF, 
                    studynum = id,
                    var.eff.size = es.var,
                    modelweights = "CORR",
                    small = FALSE)
  
# save results into a data.frame named "RESULTS"
RESULTS <- data.frame(cbind(type = "overall model", 
                            s = ffh.overall$N,
                            k = ffh.overall$M,
                            ffh.overall$reg_table))

# delete unnecessary variables
rm (ffh.overall)
```


## Moderator Analyses
### Moderators w/ two levels
#### Function for moderator analyses w/ 2-levels
```{r moderator analysis}
# This function examines moderators by including them as a predictor in a
# meta-regression with RVE (using the robu function in the robumeta package).
# Then the results are appended to a dataframe named "RESULTS".
# The user must specify the input data.frame (df) and moderator (mod).
# Note: this function is not generic; It will only work on this dataset.

MrRVEMod <- function(df, mod){
  # run meta
  ffh.mod <- robu(formula = as.formula(paste("es ~ ", mod)),
                  data = df,
                  studynum = id,
                  var.eff.size = es.var,
                  modelweights = "CORR",
                  small = FALSE)

  # save to "RESULTS" dataframe
  RESULTS <<- rbind(RESULTS, 
                    cbind(type = mod,
                          s = ffh.mod$N,
                          k = ffh.mod$M,
                          ffh.mod$reg_table))
}
```

##### Call function for moderator analyses w/ 2 levels
```{r process all moderators w/ 2 levels}
# This code will conduct moderator analyses
# using the MrRVEMod function (defined above) and lapply.
# First, we create a vector of moderator names.
# Then, using lapply, we use those names as input in MrRVEMod,
# which includes the moderator as a predictor in a meta-regression w/ RVE equation.

# We run this on moderators with two levels because the
# beta coefficient will test whether there is a difference
# between the two levels.
# However, this approach is not suitable for testing moderators with 
# more than two levels (processed next).

# create vector of moderator names
moderators <- c("dim.v.dis", "dim.pos.v.neg", "dur.manip", 
                "ini.v.mod", "file.drawer", "paq", 
                "proc.control", "proc.aware","prop.women",
                "video.know", "w.v.b")

# use lapply to call MrRVEMod function on vector of moderators
lapply(moderators, function(z){
  MrRVEMod(df = FFH.DF,
           mod = z)
  })

# delete moderator vector
rm(moderators)
```

### Moderators w/ >2 levels
To examine moderators with more than 2 levels we want to perform an omnibus test.
To do so, we first dummy code our moderators and include them in a meta-regression with RVE.
To perform the omnibus test, we use a Wald_test with small sample corrections.
This is essentially an F-test with RVE.

#### Prep results dataframe
Currently, the results dataframe does not have columns for F-test output, so we will append those columns now.
```{r RESULTS w/ F-values}
# Wald test's provide an F-value, degrees of freedom, and p-value.
# Add these columns to the RESULTS dataframe here
RESULTS <- cbind(RESULTS, 
                 "F" = NA,
                 "F.df" = NA,
                 "F.pval" = NA)
```

#### Stim
```{r stim mod analysis}
# fit a meta-regression with RVE model with stim as a predictor
stim.mr <- robu(formula = es ~ stim,
                data = FFH.DF, 
                studynum = id,
                var.eff.size = es.var,
                modelweights = "CORR",
                small = FALSE)

# run Wald_test
stim.wald <- Wald_test(obj = stim.mr, 
                       constraints = 2:7, 
                       vcov = "CR2")

# append Wald_test to RESULTS dataframe
RESULTS <- rbind(RESULTS,
                 cbind(type = "stim",
                       s = stim.mr$N,
                       k = stim.mr$M,
                       labels = "omnibus",
                       b.r = NA,
                       SE = NA,
                       t= NA,
                       dfs = NA,
                       prob = NA,
                       CI.L = NA,
                       CI.U = NA,
                       sig = NA,
                       F = stim.wald$Fstat,
                       F.df = stim.wald$df,
                       F.pval = stim.wald$p_val)
                      )

# delete unnecessary variables 
rm(stim.mr, stim.wald)
```

#### Emo
```{r emo mod analysis}
# fit a meta-regression with RVE model with emotion as a predictor
emo.mr <- robu(formula = es ~ emo,
               data = FFH.DF, 
               studynum = id,
               var.eff.size = es.var,
               modelweights = "CORR",
               small = FALSE)

# run Wald_test
emo.wald <- Wald_test(obj = emo.mr, 
                      constraints = 2:6, 
                      vcov = "CR2")

# append Wald_test to RESULTS dataframe
RESULTS <- rbind(RESULTS,
                 cbind(type = "emo",
                       s = emo.mr$N,
                       k = emo.mr$M,
                       labels = "omnibus",
                       b.r = NA,
                       SE = NA,
                       t= NA,
                       dfs = NA,
                       prob = NA,
                       CI.L = NA,
                       CI.U = NA,
                       sig = NA,
                       F = emo.wald$Fstat,
                       F.df = emo.wald$df,
                       F.pval = emo.wald$p_val)
                      )

# delete unnecessary variables
rm(emo.mr, emo.wald)

```

#### Proc (only controls)
```{r proc mod analysis 1}
# For ease of interpreting the procedure moderator, 
# we first only want to examine procedures with control groups.
# This code first creates a tmp dataframe containing only cases with control groups

# limit to cases where procedures had control groups
# using subset function
FFH.DF.TMP <- subset(FFH.DF, proc == "Botox-control"
                           | proc == "exaggerate-control"
                           | proc == "exp.pose-control"
                           | proc == "incidental-control"
                           | proc == "suppress-control")

FFH.DF.TMP$proc <- factor(FFH.DF.TMP$proc)

# fit a meta-regression with RVE model with procedure as a predictor
proc.mr <- robu(formula = es ~ proc,
                data = FFH.DF.TMP, 
                studynum = id,
                var.eff.size = es.var,
                modelweights = "CORR",
                small = FALSE)

# run Wald_test
proc.wald <- Wald_test(obj = proc.mr, 
                       constraints = 2:5, 
                       vcov = "CR2")

# append Wald_test to RESULTS dataframe
RESULTS <- rbind(RESULTS,
                 cbind(type = "proc",
                       s = proc.mr$N,
                       k = proc.mr$M,
                       labels = "omnibus",
                       b.r = NA,
                       SE = NA,
                       t= NA,
                       dfs = NA,
                       prob = NA,
                       CI.L = NA,
                       CI.U = NA,
                       sig = NA,
                       F = proc.wald$Fstat,
                       F.df = proc.wald$df,
                       F.pval = proc.wald$p_val)
                      )

# delete unnecessary variables
rm(proc.mr, proc.wald, FFH.DF.TMP)
```

#### Proc (all)
Although we believe the above code is the best test of whether procedure is a significant moderator, this next code tests whether there are differences among ALL levels of procedure (there are not).
```{r proc(all) mod analysis}
# create a meta-regression with RVE model with all procedures as a predictor
proc.all.mr <- robu(formula = es ~ proc,
                    data = FFH.DF, 
                    studynum = id,
                    var.eff.size = es.var,
                    modelweights = "CORR",
                    small = FALSE)

# run Wald_test
proc.all.wald <- Wald_test(obj = proc.all.mr, 
                           constraints = 2:10, 
                           vcov = "CR2")

# append Wald_test to RESULTS dataframe
RESULTS <- rbind(RESULTS,
                 cbind(type = "proc.all",
                       s = proc.all.mr$N,
                       k = proc.all.mr$M,
                       labels = "omnibus",
                       b.r = NA,
                       SE = NA,
                       t= NA,
                       dfs = NA,
                       prob = NA,
                       CI.L = NA,
                       CI.U = NA,
                       sig = NA,
                       F = proc.all.wald$Fstat,
                       F.df = proc.all.wald$df,
                       F.pval = proc.all.wald$p_val)
                      )

# delete unnecessary variables
rm(proc.all.mr, proc.all.wald)
```


### Theoretical moderators controlling for methodological mods
In our pre-registratin plan, we said that we would re-examine important, significant theoretical moderators controlling for significant moderators.
Our results thus far suggests that paq (type of emotion) and ini.v.mod (initiate or modulate) are significant theoretical moderators.
Stim is the only significant methodological moderator.

Note: We could not actually run this procedure on ini.v.mod, because there are, by definition, no emotional stimuli in studies that test the initiation function.
Therefore, we only examined the paq moderator controlling for stim, which did not change our conclusions.

To keep the R environment clean, the code below is set NOT to run. However, it will run if the user changes eval to TRUE.
```{r theoretical mods w/ methodological mod covar eval = FALSE}
# Using meta-regression with RVE,
# re-examine paq moderator controlling for stim.
ffh.mod <- robu(formula = es ~ stim + paq,
                data = FFH.DF,
                studynum = id,
                var.eff.size = es.var,
                modelweights = "CORR",
                small = FALSE)

# re-examine dim.v.dis moderator controlling for stim.
ffh.mod <- robu(formula = es ~ stim + dim.v.dis,
                data = FFH.DF,
                studynum = id,
                var.eff.size = es.var,
                modelweights = "CORR",
                small = FALSE)
```

### Examine decline effect
```{r create year-centered object}
# create a year variable centered at 2017
FFH.DF$year_adj <- NA
for (i in 1:nrow(FFH.DF)) {
  FFH.DF$year_adj[i] <- FFH.DF$year[i] - 2017
}
```

#### In overall model
```{r decline effect in overall dataset}
# plot and test relationship between year and es
plot(FFH.DF$year, FFH.DF$es)
cor.test(x = FFH.DF$year, 
         y = FFH.DF$es)

# regress es with year (centered at 2017)
ffh.decline <- robu(formula = es ~ year_adj,
                    data = FFH.DF, 
                    studynum = id,
                    var.eff.size = es.var,
                    modelweights = "CORR",
                    small = FALSE)

# save to results dataframe
RESULTS <<- rbind(RESULTS, 
                  cbind(type = "year_adj",
                        s = ffh.decline$N,
                        k = ffh.decline$M,
                        ffh.decline$reg_table,
                        F = NA,
                        F.df = NA,
                        F.pval = NA))

# delete unnecessary objects
rm(ffh.decline)
```

##### Without registered replications
```{r decline in overall dataset excluding RRR's}
# SENSITIVITY ANALYSIS
# regress es with year (centered at 2017), excluding registered replications
  ## exclude RRR's
    ### identify RRR'S
    FFH.DF.TMP <- FFH.DF
    
    FFH.DF.TMP$RRR <- ""
    for (i in 1:nrow(FFH.DF.TMP)) {
      if (FFH.DF.TMP$id[i] > 70 & FFH.DF.TMP$id[i] < 88){
        FFH.DF.TMP$RRR[i] <- "yes"  
      }
    }

    ### exclude RRR's in tmp dataframe
    FFH.DF.TMP <- subset(FFH.DF.TMP, FFH.DF.TMP$RRR != "yes" &
                                     paq != "yes")

  ## regress es with year (centered at 2017), 
  ## excluding registerd replications  
  ffh.decline.noRRR <- robu(formula = es ~ year_adj,
                            data = FFH.DF.TMP, 
                            studynum = id,
                            var.eff.size = es.var,
                            modelweights = "CORR",
                            small = FALSE)

# remove unnecessary objects
rm (FFH.DF.TMP, ffh.decline.noRRR)
```


#### In emotional experience model
```{r decline effect in emotional experience dataset}
# limit to emotional experience variables
FFH.DF.TMP <- subset(FFH.DF, paq == "no")

# regress es with year
ffh.decline.emo <- robu(formula = es ~ year_adj,
                        data = FFH.DF.TMP, 
                        studynum = id,
                        var.eff.size = es.var,
                        modelweights = "CORR",
                        small = FALSE)

# remove unnecessary objects
rm(ffh.decline.emo)
```

##### Without registered replications
```{r}
# SENSITIVITY ANALYSIS
# regress es with year (centered at 2017), excluding registered replications
  ## exclude RRR's
    ### identify RRR'S
    FFH.DF.TMP$RRR <- ""
    for (i in 1:nrow(FFH.DF.TMP)) {
      if (FFH.DF.TMP$id[i] > 70 & FFH.DF.TMP$id[i] < 88){
        FFH.DF.TMP$RRR[i] <- "yes"  
      }
    }

    ### exclude RRR's in tmp dataframe
    FFH.DF.TMP <- subset(FFH.DF.TMP, FFH.DF.TMP$RRR != "yes" &
                                     paq != "yes")

    ## regress es with year
    ## RRR's excluded
    ffh.decline.emo.noRRR <- robu(formula = es ~ year_adj,
                                  data = FFH.DF.TMP, 
                                  studynum = id,
                                  var.eff.size = es.var,
                                  modelweights = "CORR",
                                  small = FALSE)
# delete unnecessary objects
rm(FFH.DF.TMP, ffh.decline.emo.noRRR)
```


## Overall publication bias
### Define publication bias test function
```{r PubBiasTests}
# Publication bias function
# 1. To examine publication bias using aggregated dependent effect sizes
## 1.1. To set up pub bias tests:
###    - 1.1.a. Aggregate dependent effect sizes
###    - 1.1.b. Run a random-effects meta-regression model
## 1.2. Perform publication bias tests:
###    - 1.2.a. Funnel-plot (save output to global env.)
###    - 1.2.b. Trim-and-fill (save output)
###    - 1.2.c. Fail-safe N (save output)
###    - 1.2.d. PET-PEESE (save output)
###    - 1.2.e. Weight-function model (save output)
# 2. Examine PET-PEESE w/ RVE:
## 2.1. PET-PEESE w/ RVE (save output)
# 3. Put results in list.
#
# The user specifies: 1) the dataframe, 2) name of results list.
# Note: this function is not generic; It will only work on this dataset.

PubBiasTests <- function(df, agg.cor = .5, list.name){
  #===================================================================
  # 1. Examine publication bias using aggregated dependent effect sizes
  #===================================================================
    #**********************************
    # 1.1. Set up publication bias tests
    #**********************************
    ## 1.1.a. aggregate
    FFH.AGG.DF <- agg(id = id,
                      es = es,
                      var = es.var,
                      method = "BHHR",
                      cor = agg.cor, 
                      data = df)
      
    ## 1.1.b. run meta-analysis  
    ffh.agg.mr <- rma.uni(yi = es,
                          vi = var,
                          data = FFH.AGG.DF,
                          method = "REML")
    
    #********************************** 
    # 1.2. Perform publication bias tests
    #**********************************
    ## 1.2.a. Funnel plot using funnel function in metafor package
    funnel(x = ffh.agg.mr, 
           yaxis = "sei",
           xlab = "Cohen's standardized d")
    
      # save funnel plot as object
      funnel.plot <- recordPlot()
    
      # clear R environment
      plot.new()
      
    ## 1.2.b. Duval and Tweedie trim and fill method
    ## using the trimfill function in the metafor package
    trim <- trimfill(x = ffh.agg.mr)
    
    ## 1.2.c. Rosenberg fail-safe N 
    ## using the fsn function in the metafor package
    fail.safe.n <- fsn(yi = es,
                       vi = var,
                       data = FFH.AGG.DF,
                       type = "Rosenberg",
                       alpha = .05)
  
    ## 1.2.d. PET-PEESE models
      ### syntax provided by Carter & McCullough, 2014
      ### first compute standard error of es
      FFH.AGG.DF$se <- sqrt(FFH.AGG.DF$var)
      ### create models
      pet <-   lm(FFH.AGG.DF$es ~ FFH.AGG.DF$se, 
                   weights = 1 / FFH.AGG.DF$var) 
      peese <- lm(FFH.AGG.DF$es ~ FFH.AGG.DF$var, 
                   weights = 1 / FFH.AGG.DF$var)
  
    ## 1.2.e. Vevea and Hedges (1995) Weight-Function Model
    ## using weightfunct function in the weightr package
    weight.funct <- weightfunct(effect = FFH.AGG.DF$es,
                                 v = FFH.AGG.DF$var,
                                 mods = NULL,
                                 weights= NULL,
                                 fe = FALSE,
                                 table = TRUE,
                                 pval = NULL)
      
  #===================================================================
  # 1. Examine PET-PEESE with RVE:
  #===================================================================
    #**********************************
    # 1.1. PET-PEESE w/ RVE
    #**********************************
    # PET.rve
    pet.rve <- robu(formula = es ~ se,
                    data = df, 
                    studynum = id,
                    var.eff.size = es.var,
                    modelweights = "CORR",
                    small = FALSE)

    # PEESE.rve
    peese.rve <- robu(formula = es ~ es.var,
                      data = df, 
                      studynum = id,
                      var.eff.size = es.var,
                      modelweights = "CORR",
                      small = FALSE)
      
  #==================================
  # 3. Put results in list
  #==================================
  assign(x= list.name,
         value = list(funnel = funnel.plot,
                      trim = trim,
                      fail.safe.n = fail.safe.n,
                      pet = summary(pet), 
                      peese = summary(peese),
                      weight.funct = weight.funct,
                      pet.rve = pet.rve,
                      peese.rve = peese.rve),
         envir = .GlobalEnv)
}
```

### Call function for publication bias tests
```{r call PubBiasTests}
PubBiasTests(df = FFH.DF,
             list.name = "bias.results")
```

### Publication bias results list
The PubBiasTests function called above put all the results in a list called bias.results.

Below are commands to call the specific data:
  bias.results$funnel
  bias.results$trim
  bias.results$fail.safe.n
  bias.results$pet
  bias.results$peese
  bias.results$weight.funct
  bias.results$pet.rve
  bias.results$peese.rve


# ****Section 4: Sensitivity Analyses****
# Impact of outliers
This code takes awhile to run, so it currently set not to. The user can make it run by changing eval in the next four sections to "TRUE".

Note: this code identifies 8 influential outliers. When we removed them our results remained unchanged. 
## Identify outliers
```{r identify outliers eval = FALSE}
# To check for influential outliers, this code first creates a standard
# intercept-only random-effects meta-regression model,
# then uses the influence function to flag influential outliers
# Note: this approach does not currently work with RVE meta-regression.

# create a standard meta-regression model.
ffh.mr <- rma.uni (yi = es,
                   vi = es.var,
                   data = FFH.DF,
                   method = "REML")

# identify influential outliers
outlier.detection <- influence(ffh.mr)

# save influential outlier case numbers in vector
outliers <- which(outlier.detection$is.infl == "TRUE")

# remove outliers
# two in the negative direction,the rest in the positive direction
FFH.NO.OUTLIER.DF <- FFH.DF[-outliers,]

# remove meta model
rm (ffh.mr)
```

## Overall effect (no outliers)
```{r meta no outlier eval = FALSE}
# (excluding outliers)
# meta-regression with robust variance estimates 
# using the robu function in the robumeta package
meta.no.outlier <- robu(formula = es ~ 1,
                       data = FFH.NO.OUTLIER.DF, 
                       studynum = id,
                       var.eff.size = es.var,
                       modelweights = "CORR",
                       small = FALSE)
```

## Overall publication bias (no outliers)
```{r bias no outliers eval = FALSE}
PubBiasTests(df = FFH.DF,
             list.name = "bias.no.outlier")
```

## Put outlier analyses in list
Commands to call data:
  outlier.results$outlier.test
  outlier.results$influential.outliers
  outlier.results$meta.no.outlier
  outlier.results$bias.no.outlier
```{r list outlier analyses eval = FALSE}
# Put outlier sensitivity analyses in a list 
outlier.results <- list(outlier.test = outlier.detection,
                        influential.outliers = outliers,
                        meta.no.outlier = meta.no.outlier,
                        bias.no.outlier = bias.no.outlier)

# delete unnecessary variables
rm (outlier.detection, outliers, meta.no.outlier,
   bias.no.outlier, FFH.NO.OUTLIER.DF)
```


# Publication bias sensitivity analysis
## Split by significant moderators 
### Split by PAQ
```{r bias tests split by paq}
# using mapply function:
# call PubBiasTests function (defined above)
# split the dataframe by the moderator (using split function),
# build list.name using levels of split moderator (using paste and split)
mapply(FUN = PubBiasTests, 
       df = split(FFH.DF, FFH.DF$paq), 
       list.name = paste("paq",
                         names(split(FFH.DF, FFH.DF$paq)),
                         "bias",
                         sep = "."))
```

#### Pub bias sens for paq.no
##### Excluding suppression
```{r bias tests with no suppress}
# create tmp dataset that excludes suppressions studies and paq.yes
FFH.DF.TMP <- subset(FFH.DF, proc != "Botox-control" &
                             proc != "suppress-control" &
                             paq != "yes")

# call PubBiasTests function (defined above)
PubBiasTests(df = FFH.DF.TMP,
             list.name = "paqn.sens.no.supp")

# remove tmp dataset
rm(FFH.DF.TMP)
```

##### Excluding RRR's
```{r bias tests with no RRR's}
# make tmp dataframe
FFH.DF.TMP <- FFH.DF

# identify RRR's (id's 71-87)
FFH.DF.TMP$RRR <- ""
for (i in 1:nrow(FFH.DF.TMP)) {
  if (FFH.DF.TMP$id[i] > 70 & FFH.DF.TMP$id[i] < 88){
    FFH.DF.TMP$RRR[i] <- "yes"  
  }
}

# exclude RRR's in tmp dataframe
FFH.DF.TMP <- subset(FFH.DF.TMP, FFH.DF.TMP$RRR != "yes" &
                                 paq != "yes")

# call PubBiasTests function (defined above)
PubBiasTests(df = FFH.DF.TMP,
             list.name = "paqn.sens.no.RRR")

# remove tmp dataframe
rm(FFH.DF.TMP)
```

##### Excluding RRR's and unpublished data
```{r funnel no RRR's or unpublished data}
# make tmp dataset
FFH.DF.TMP <- FFH.DF

# identify RRR's (id's 71-87)
FFH.DF.TMP$RRR <- ""
for (i in 1:nrow(FFH.DF.TMP)) {
  if (FFH.DF.TMP$id[i] > 70 & FFH.DF.TMP$id[i] < 88){
    FFH.DF.TMP$RRR[i] <- "yes"  
  }
}

# exclude RRR's, unpublished data, and paq.yes in tmp dataset
FFH.DF.TMP <- subset(FFH.DF.TMP, RRR != "yes" &
                                 file.drawer != "yes" &
                                 paq != "yes")

# call PubBiasTests function (defined above)
PubBiasTests(df = FFH.DF.TMP,
             list.name = "paqn.sens.no.RRR.unpub")

# delete tmp dataset
rm(FFH.DF.TMP)
```

#### Put paq.no sens analyses in list
```{r paq.n.sens}
# put paq.no sens analyses in list
paq.no.sens <- list(no.supp = paqn.sens.no.supp,
                    no.RRR = paqn.sens.no.RRR,
                    no.RRR.unpub = paqn.sens.no.RRR.unpub)

# remove unnecessary variables
rm (paqn.sens.no.supp, paqn.sens.no.RRR, paqn.sens.no.RRR.unpub)
```


### Split by Initiate versus Modulate
```{r bias tests split by initiate.v.modulate}
# using mapply function:
# call PubBiasTests function (defined above)
# split the dataframe by the moderator (using split function),
# build list.name using levels of split moderator (using paste and split)
mapply(FUN = PubBiasTests, 
       df = split(FFH.DF, FFH.DF$ini.v.mod), 
       list.name = paste(names(split(FFH.DF, FFH.DF$ini.v.mod)),
                         "bias",
                         sep = "."))
```

### Split by Stim
```{r bias tests split by stim}
# using mapply function:
# call the PubBiasTests function (defined above)
# split the dataframe by the moderator (using split function),
# build list.name using levels of split moderator (using paste and split)
# NOTE: with such few observations for some levels of this moderator, 
# some estimations will be problematic.

# filter out levels with too few obserations
FFH.DF.TMP <- subset(FFH.DF, stim != "stories" &
                             stim != "sentences" &
                             stim != "imagined scenarios")

FFH.DF.TMP$stim <- factor(FFH.DF.TMP$stim)  #  must reset factor levels

# run mapply
mapply(FUN = PubBiasTests, 
       df = split(FFH.DF.TMP, FFH.DF.TMP$stim), 
       list.name = paste(names(split(FFH.DF.TMP, FFH.DF.TMP$stim)),
                         "bias",
                         sep = "."))

# delete tmp dataframe
rm(FFH.DF.TMP)
```

## Put publication bias sensitivity lists in a list
The code below creates a nested list of publication bias sensitivity results.

Directions for specifying desired output are below:
1) bias.sens
2) Choose sensitivity parameter:
  $paq.no
  $paq.no.sens
  $paq.yes
  $initiate
  $modulate
  $audio
  $film
  $pictures
  $social.context

3) Choose analysis:
  $funnel
  $trim
  $fail.safe.n
  $pet
  $peese
  $weight.funct

For examples:
a) to examine all bias analyses for all paramters, call: bias.sens
b) to examine all bias analyses for initiate data, call: bias.sens$initiate
c) to examine PEESE for initiate data, call: bias.sens$initiate$peese

This list also contains the results for the paq.no sensitivity analysis. This includes analyses:
1) excluding suppression (bias.sens$paq.no.sens$no.supp)
2) excluding RRR's (bias.sens$paq.no.sens$no.RRR)
3) excluding RRR's and unpublished data (bias.sens$paq.no.sens$no.RRR.unpub)

```{r Put pub bias sensitivity results in list}
# put trim, fail-safe, PET, PEESE, weight.funct results in a list
bias.sens <- list(paq.no = paq.no.bias,
                  paq.yes = paq.yes.bias,
                  paq.no.sens = paq.no.sens,
                  initiate = initiate.bias,
                  modulate = modulate.bias,
                  audio = audio.bias,
                  film = film.bias,
                  pictures = pictures.bias,
                  social.context = `social context.bias`)

# delete unnecessary objects
rm(paq.no.bias, paq.yes.bias, paq.no.sens,
   initiate.bias, modulate.bias, 
   audio.bias, film.bias, pictures.bias,`social context.bias`)
```

# Additional sensitivity analyses
## !!!Assumed pre-post corr in within-subject designs
To calculate Cohen's d for within-subjects design we need the correlation between the pre- and post- measures. However,this correlation is rarely reported in the literature, so we had to assume values. Earlier, we assumed a correlation of .5. Here we will perform a sensitivity analysis on that assumed value.

NOTE: Thank you Ashley Kuelz for pointing out that this code is buggy. For now, it is set to not run. To manually examine the impact of the asummed pre-post correlation in within-subject designs, change the value of corr on line 269, then run the code up to line 560.
### Function that calculates es and es.var for within-subject designs
```{r EsWitn eval = FALSE}
# to make code cleaner, 
# this function calls all the user-defined functions that
# compute effect size for within-subject designs (all defined earlier).
# Note: this function is not generic; It will only work on this dataset.

EsWitn <- function(){
  # call EsWitnMean on cases with within-subject designs and *means*
  for (i in 1:nrow(FFH.DF)) {
    if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "mean") {
      FFH.DF$es[i] <<- EsWitnMean (m.1 = FFH.DF$w.treat.m[i],
                                  sd.1 = FFH.DF$w.treat.sd[i],
                                  m.2 = FFH.DF$w.compa.m[i],
                                  sd.2 = FFH.DF$w.compa.sd[i],
                                  corr = corr)
    }
  }
  
  
  # call EsWitnTval on cases with within-subject designs and *t-values*
  for (i in 1:nrow(FFH.DF)) {
    if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "tval") {
      FFH.DF$es[i] <<- EsWitnTval (n = FFH.DF$w.n[i],
                                  tval = FFH.DF$w.tval[i],
                                  corr = corr)
    }
  }
  
  # call EsWitnFval on cases with within-subject designs and *F-values*
  for (i in 1:nrow(FFH.DF)) {
    if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "fval") {
      FFH.DF$es[i] <<- EsWitnFval (n = FFH.DF$w.n[i],
                                  fval = FFH.DF$w.fval[i],
                                  corr = corr,
                                  direction = FFH.DF$es.dir.fpval[i])
    }
  }
  
  # call EsWitnPval on cases with within-subject designs and *p-values*
  for (i in 1:nrow(FFH.DF)) {
    if (FFH.DF$w.v.b[i] == "within" & FFH.DF$es.calc.method[i] == "pval") {
      FFH.DF$es[i] <<- EsWitnPval (n = FFH.DF$w.n[i],
                                  pval = FFH.DF$w.pval[i],
                                  pval.df = FFH.DF$w.pval.df[i],
                                  corr = corr,
                                  direction = FFH.DF$es.dir.fpval[i])
    }
  }
  
  # call EsVarWitn on cases with within subject designs
  for (i in 1:nrow(FFH.DF)) {
    if (FFH.DF$w.v.b[i] == "within") {
      FFH.DF$es.var[i] <<- EsVarWitn (n = FFH.DF$w.n[i],
                                     es = FFH.DF$es[i])
    }
  }

  # calculate se of d
  FFH.DF$se <<- sqrt(FFH.DF$es.var)
}
```

### Call function
```{r Sens: pre-post corr eval = FALSE}
# This code performs sensitivity analysis on the assumed pre-post
# correlation in the calculation of effect size in within-subject designs.
#
# Using lapply, this code does the following for each value in a vector
# of correlations (named corr.list):
# 1) Calculate effect sizes for within-subjects designs, 
# 2) Run a overall meta-regression with robust variance estimates
# 3) Append the results in a dataframe named "ES.CALC.CORR.SENS".


# create a backup of the dataframe 
# (we will restore this backup after the sensitivity analysis)
FFH.DF.BACKUP <- FFH.DF

# create a blank dataframe for results of sensitivity analysis
ES.CALC.CORR.SENS <- data.frame()

# creat a blank correlation vector (needed for below lapply to work)
corr <- NA

# vector of correlation values to test
corr.list <- c(.10, .30, .50, .70, .90)

# lapply
lapply(corr.list, function(z){
  # set assumed correlation
  corr <- z
  print(corr)
  # re-calculate within-subject effect sizes using EsWitn function
  EsWitn()
  # calculate overall effect size using meta-regression with RVE
  ffh.overall.tmp <- robu(formula = es ~ 1,
                          data = FFH.DF, 
                          studynum = id,
                          var.eff.size = es.var,
                          modelweights = "CORR",
                          small = FALSE)
  
  # save results into dataframe
  ES.CALC.CORR.SENS <<- rbind(ES.CALC.CORR.SENS, 
                              cbind(corr = z, ffh.overall.tmp$reg_table)) 
  
} )

# restore pristine dataframe, delete corr.list and functions
FFH.DF <- FFH.DF.BACKUP
rm(FFH.DF.BACKUP,corr.list, EsBetwFval, 
   EsBetwMean, EsBetwPval, EsBetwTval, 
   EsWitnFval, EsWitnMean, EsWitnPval,
   EsWitnTval, EsVarBetw, EsVarWitn, 
   EsWitn, i, corr)
```

## Assumed effect size correlation in RVE method
In meta-regression with RVE the default assumed within-study effect-size correlation is r = .80 (a relatively conservative value). We pre-registered this as the default value to inform our conclusions, but performed additional analyses to determine the impact of this assumed value on our overall effect meta-regression model.
```{r Sens: RVE corr}
# re-create overall model
ffh.overall <- robu(formula = es ~ 1,
                    data = FFH.DF, 
                    studynum = id,
                    var.eff.size = es.var,
                    modelweights = "CORR",
                    small = FALSE)

# perform sensitivity analysis
# using sensitivity function in robumeta package
FFH.OVERALL.SENS <- sensitivity(ffh.overall)

# delete overall model
rm(ffh.overall)
```

## Assumed effect size correlation in aggregation method
When aggregating dependent effect sizes using the Borenstein method, the meta-analyst must specify the correlation between the dependent effect sizes. Earlier, we assumed a correlation of .5. Here we perform a sensitivity analysis on that assumed value.
```{r sens: Borenstein aggregation corr}
# create a vector of assumed correlations to test
  agg.corr <- c(.1, .3, .5, .7, .9)

# run PubBias analyses using lapply
# run lapply on the vector of assumed correlation
lapply(agg.corr, function(x){
  PubBiasTests(df = FFH.DF,
               agg.cor = x,
               list.name = paste0("agg.corr", x))
})

# put agg.corr.sens results into a alist
agg.corr.sens <- list(corr0.1 = agg.corr0.1,
                      corr0.3 = agg.corr0.3,
                      corr0.5 = agg.corr0.5,
                      corr0.7 = agg.corr0.7,
                      corr0.9 = agg.corr0.9)

# delete unnecessary variables
rm(agg.corr0.1, agg.corr0.3, agg.corr0.5,
   agg.corr0.7, agg.corr0.9,
   agg.corr)
```

## Put additional sensitivity results in a list
Directions for specifying desired output:
- addt.sens.analyses$es.calc.corr
- addt.sens.analyses$rve.corr
- addt.sens.analyses$agg.corr.sens

```{r Put sensitivity results in list}
# put sensitivity results in a list
addt.sens.analyses <- list(es.calc.corr = ES.CALC.CORR.SENS,
                          rve.corr= FFH.OVERALL.SENS,
                          agg.corr.sens = agg.corr.sens)

# delete unnecessary objects
rm(ES.CALC.CORR.SENS, FFH.OVERALL.SENS, agg.corr.sens)
```


# ****Section 5: Exploratory Analyses****
# Different Meta-analytic approaches
## Robust variance estimates (corr weighting)
```{r RVE corr weighting}
# examine overall model using meta-regression with RVE 
# using correlated-effects weighting
# Note: this is the standard approach we used in this project.
rve.corr <- robu(formula = es ~ 1,
                 data = FFH.DF, 
                 studynum = id,
                 var.eff.size = es.var,
                 modelweights = "CORR", #  *run as hier
                 small = FALSE)
```

## Aggregated dependent effect sizes
```{r aggregation method}
# aggregate dependent effect sizes
FFH.AGG.DF <- agg(id = id,
                  es = es,
                  var = es.var,
                  method = "BHHR",
                  cor = .5, 
                  data = FFH.DF)

# examine overall model using a random-effects intercept-only meta-regression model
# with aggregated dependent effect sizes
ffh.agg.mr <- rma.uni(yi = es,
                      vi = var,
                      data = FFH.AGG.DF,
                      method = "REML")

# delete unnecessary aggregated dataframe
rm(FFH.AGG.DF)
```

## Random-effects meta-regression without RVE
```{r random-effects}
# traditional random-effects intercept-only meta-regression model
# with no correctiosn for dependencies
ffh.mr <- rma.uni(yi = es,
                  vi = es.var,
                  data = FFH.DF,
                  method = "REML")
```

## Put results from different approaches in a list
Directions for specifying desired output:
- other.meta.approach$rve.corr
- other.meta.approach$ffh.agg
- other.meta.approach$ffh.reml
```{r Put different approaches in list}
# put different meta-analytic approach results in a list
compare.meta.approach <- list(rve.corr = rve.corr$reg_table,
                              ffh.agg = ffh.agg.mr,
                              ffh.reml = ffh.mr)

# delete unnecessary objects
rm(rve.corr, ffh.agg.mr, ffh.mr )
```

# Exploratory weighting of RRR
```{r exp.weight.RRR}
# Using meta-analysis with aggregated dependent effect size, this code:
# 1) Appends the default weight of each study to the dataframe
# 2) Identifies registered replication studies 
# 3) For each value in a vector of "weight multiples":
#   - Multiply registered replications by the weight multiple 
#   - Re-run meta-analysis using new weights
#   - Calculate how much relative weight was given the the registered replications
#   - Paste results in a results dataframe named "EXP.WEIGHT"
# Note: this function is not generic; It will only work on this dataset.

### Steps 1 and 2 ###
# aggregate dependent effect sizes
FFH.AGG.DF <- agg(id = id,
                  es = es,
                  var = es.var,
                  method = "BHHR",
                  cor = .5, 
                  data = FFH.DF)

# re-run meta-analysis to figure out default weighting
ffh.agg.mr <- rma.uni(yi = es,
                      vi = var,
                      data = FFH.AGG.DF,
                      method = "REML")

# create a tmp dataframe and append default weighting to dataframe
FFH.AGG.DF.TMP <- FFH.AGG.DF
FFH.AGG.DF.TMP$weight <- weights.rma.uni(ffh.agg.mr)
  # create a blank column for experimental weights 
  FFH.AGG.DF.TMP$weight.exp <- NA

# identify registered replications
FFH.AGG.DF.TMP$RRR <- NA
for (i in 1:nrow(FFH.AGG.DF.TMP)) {
  if (FFH.AGG.DF.TMP$id[i] > 70 & FFH.AGG.DF.TMP$id[i] < 88){
    FFH.AGG.DF.TMP$RRR[i] <- "yes"  
  }
}

# create a dataframe that results will be pasted in
EXP.WEIGHT <- data.frame()

# create a vector containing weight multiples to be tested
weight.mult <- seq(1,10,.1)
######


### Step 3 ### 
for (w in weight.mult){
  # calculate weights
  for (i in 1:nrow(FFH.AGG.DF.TMP)) {
    if (!is.na(FFH.AGG.DF.TMP$RRR[i])){
      #  if RRR, multiple weight by weight.mult
      FFH.AGG.DF.TMP$weight.exp[i] <- FFH.AGG.DF.TMP$weight[i] * w 
    } else {
      # if not RRR, keep weight same
      FFH.AGG.DF.TMP$weight.exp[i] <- FFH.AGG.DF.TMP$weight[i] 
    }
  }
  
  # re-run meta-analysis with experimental weights
  ffh.agg.mr.tmp <- rma.uni(yi = es,
                            vi = var,
                            weights = weight.exp,
                            data = FFH.AGG.DF.TMP,
                            method = "REML")
  
  #calculate how much relative weight RRR's were given
  rel.weight <- (colSums (subset (FFH.AGG.DF.TMP, subset = (RRR == "yes"), select = weight.exp))) / #  weight of subset divided by
                (colSums (subset (FFH.AGG.DF.TMP, select = weight.exp)))                            #  weight of all cases
  
  # paste into dataset
  EXP.WEIGHT<- rbind(EXP.WEIGHT, cbind(weight = w, pval = ffh.agg.mr.tmp$pval, rel.weight = rel.weight))
}
  
# Visualize weight.exp findings
plot.new()

plot (x = EXP.WEIGHT$rel.weight, 
      y= EXP.WEIGHT$pval,
      main = "p-value of overall facial feedback effect 
              \nby relative weight given to registered replications",
      xlab = "Proportion of weight given to registered replications",
      ylab = "p-value of overall effect",
      pch = 20, #/  solid circles
      abline (h = .05, col = "red"),
      cex.main = 1.5) #/ add a red line at p = .05
  
# delete vistigial
rm (FFH.AGG.DF.TMP, weight.mult, ffh.agg.mr.tmp, rel.weight, w,
    FFH.AGG.DF, ffh.agg.mr)
```


## (Initiate v. Modulate) x (Discrete v. Dimensional)
```{r}
# Initiate Discrete (d = .51)
FFH.DF.TMP <- subset(FFH.DF, ini.v.mod == "initiate" &
                             dim.v.dis == "discrete")

  robu(formula = es ~ 1,
       data = FFH.DF.TMP, 
       studynum = id,
       var.eff.size = es.var,
       modelweights = "CORR",
       small = FALSE)

# Initiate Dimensional (d = .15, p =.13)
FFH.DF.TMP <- subset(FFH.DF, ini.v.mod == "initiate" &
                             dim.v.dis == "dimensional")

  robu(formula = es ~ 1,
       data = FFH.DF.TMP, 
       studynum = id,
       var.eff.size = es.var,
       modelweights = "CORR",
       small = FALSE)

# Modulate Discrete (d = .11)
FFH.DF.TMP <- subset(FFH.DF, ini.v.mod == "modulate" &
                             dim.v.dis == "discrete")

  robu(formula = es ~ 1,
       data = FFH.DF.TMP, 
       studynum = id,
       var.eff.size = es.var,
       modelweights = "CORR",
       small = FALSE)
  
# Modulate Dimensional (d = .13)
FFH.DF.TMP <- subset(FFH.DF, ini.v.mod == "modulate" &
                             dim.v.dis == "dimensional")

  robu(formula = es ~ 1,
       data = FFH.DF.TMP, 
       studynum = id,
       var.eff.size = es.var,
       modelweights = "CORR",
       small = FALSE)
```


#****Section 6: Reviewer requested exploratory analyses****
Create list to put all exploratory results in
```{r}
explr.results <- list()
```

# Weight-function analysis controlling for significant moderators
Create a list to put exploratory weight-function analyses in
```{r}
explr.weight <- list()
```

## PAQ
```{r}
explr.weight.paq <- weightfunct(effect = FFH.DF$es,
                                v = FFH.DF$es.var,
                                mods = ~FFH.DF$paq,
                                weights= NULL,
                                fe = FALSE,
                                table = TRUE,
                                pval = NULL)
```

## Initiate vs. Modulate
```{r}
explr.weight.ini <- weightfunct(effect = FFH.DF$es,
                                v = FFH.DF$es.var,
                                mods = ~FFH.DF$ini.v.mod,
                                weights= NULL,
                                fe = FALSE,
                                table = TRUE,
                                pval = NULL)
```

## Stim
```{r}
explr.weight.stim <-  weightfunct(effect = FFH.DF$es,
                                  v = FFH.DF$es.var,
                                  mods = ~FFH.DF$stim,
                                  weights= NULL,
                                  fe = FALSE,
                                  table = TRUE,
                                  pval = NULL)
```

### Put results in list
```{r}
#Put xploratory weight-function analyses in list
explr.weight <- list (paq = explr.weight.paq,
                      ini.v.mod = explr.weight.ini,
                      stim = explr.weight.stim)

rm(explr.weight.paq, explr.weight.ini, explr.weight.stim)
```

#3-level meta-analytic model
```{r}
# for the MLM, we need:
# (1) a column for study id (which is already defined as id)
# (2) a column for effect size id
# This code creates an effect size id column

FFH.DF <- FFH.DF %>%
  group_by(id) %>%
  mutate(es.id = row_number())

```

## Overall model fitting
```{r}
# overall model
overall <- rma.mv(y = es, V = es.var,
                  random = list( ~ 1 | es.id, ~ 1 | id),
                  tdist = TRUE,
                  data = FFH.DF)

# test whether estimated level 2 variance is necessary
modelnovar2 <- rma.mv(y = es, V = es.var,
                      random = list( ~ 1 | es.id, ~ 1 | id),
                      sigma2 = c(0,NA),
                      tdist = TRUE,
                      data = FFH.DF)

## compare fit
anova (overall, modelnovar2)
rm(modelnovar2)
### note: the three-level model does not provide much better fit, but the one-sided p-value is close to significance, so we will keep it in the model
```

## Moderator analyses
```{r}
# create vector of moderator names
moderators <- c("dim.v.dis", "dim.pos.v.neg", "dur.manip", 
                "ini.v.mod", "file.drawer", "paq", 
                "proc.control", "prop.women", "video.know", 
                "w.v.b", "stim", "emo", "proc")

# lapply function
lapply(moderators, function(z){
  tmp <- rma.mv(y = es, V = es.var, mods = as.formula(paste("~", z)),
                random = list( ~ 1 | es.id, ~ 1 | id),
                tdist = TRUE,
                data = FFH.DF)
  
  assign(x= z,
         value = tmp,
         envir = .GlobalEnv)
  })

# put all output into a list
results.3l <- list(overall = overall,
                   dim.v.dis = dim.v.dis, 
                   dim.pos.v.neg = dim.pos.v.neg, 
                   dur.manip = dur.manip, 
                   ini.v.mod = ini.v.mod, 
                   file.drawer = file.drawer, 
                   paq = paq, 
                   proc.control = proc.control, 
                   prop.women = prop.women, 
                   video.know = video.know, 
                   w.v.b = w.v.b, 
                   stim = stim, 
                   emo = emo,
                   proc = proc)

rm(overall, dim.v.dis, dim.pos.v.neg, dur.manip, 
   ini.v.mod, file.drawer, paq, proc.control, 
   prop.women, video.know, w.v.b, stim, emo, proc)

```
